# conda activate allpy310

'''
–ê–≤—Ç–æ–∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ —Å –æ—Ö—Ä–∞–Ω–Ω–æ–π –∫–∞–º–µ—Ä—ã ‚Äî –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è —Å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ–º:
–ì–µ–¥ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–º–æ:
- –û—Ö—Ä–∞–Ω–∞ –¥–æ–º–∞ / –æ—Ñ–∏—Å–∞ / —Å–∫–ª–∞–¥–∞
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ñ–∏–∫—Å–∞—Ü–∏—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
- –ú–∏–Ω–∏ —Å–∏—Å—Ç–µ–º–∞ –≤–∏–¥–µ–æ–Ω–∞–±–ª—é–¥–µ–Ω–∏—è –±–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞
- –ê–Ω–∞–ª–∏–∑ –∑–∞–ø–∏—Å–µ–π –Ω–∞ –ø–æ—Ç–æ–º
'''

import cv2
import time
import os

VIDEO_SOURCE = 0  # 0 = –≤–µ–±–∫–∞–º–µ—Ä–∞, –∏–ª–∏ URL/IP –∫–∞–º–µ—Ä—ã, –∏–ª–∏ –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É
SAVE_DIR = "motion_frames"
os.makedirs(SAVE_DIR, exist_ok=True)

cap = cv2.VideoCapture(VIDEO_SOURCE)
_, prev_frame = cap.read()
prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
prev_frame = cv2.GaussianBlur(prev_frame, (21, 21), 0)

frame_id = 0

print("üìπ –ó–∞–ø—É—â–µ–Ω –∞–Ω–∞–ª–∏–∑. Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.")

try:
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (21, 21), 0)

        diff = cv2.absdiff(prev_frame, gray)
        thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)[1]
        motion_percent = (cv2.countNonZero(thresh) / thresh.size) * 100

        if motion_percent > 1.0:
            filename = f"{SAVE_DIR}/motion_{frame_id}.jpg"
            cv2.imwrite(filename, frame)
            print(f"üì∏ –î–≤–∏–∂–µ–Ω–∏–µ! –°–æ—Ö—Ä–∞–Ω–∏–ª –∫–∞–¥—Ä: {filename}")

        prev_frame = gray
        frame_id += 1
        time.sleep(0.2)
except KeyboardInterrupt:
    print("üõë –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
finally:
    cap.release()